@string{PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.}}
@string{IJCV = {Int. J. Comput. Vis.}}
@string{CVPR = {IEEE Conf. Comput. Vis. Pattern Recog.}}
@string{ICCV = {Int. Conf. Comput. Vis.}}
@string{ECCV = {Eur. Conf. Comput. Vis.}}
@string{NIPS = {Adv. Neural Inform. Process. Syst.}}
@string{ICPR = {Int. Conf. Pattern Recog.}}
@string{BMVC = {Brit. Mach. Vis. Conf.}}
@string{TOG = {ACM Trans. Graph.}}
@string{TIP = {IEEE Trans. Image Process.}}
@string{TVCG = {IEEE Trans. Vis. Comput. Graph.}}
@string{TMM = {IEEE Trans. Multimedia}}
@string{ACMMM = {ACM Int. Conf. Multimedia}}
@string{ICME = {Int. Conf. Multimedia and Expo}}
@string{ICASSP = {ICASSP}}
@string{ICIP = {IEEE Int. Conf. Image Process.}}
@string{ACCV = {ACCV}}
@string{ICLR = {Int. Conf. Learn. Represent.}}
@string{IJCAI = {IJCAI}}
@string{PR = {Pattern Recognition}}
@string{AAAI = {AAAI}}
@string{CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.}}
@string{CSVT = {IEEE Trans. Circuit Syst. Video Technol.}}

@string{SPL = {IEEE Sign. Process. Letters}}
@string{VR = {Vis. Res.}}
@string{JOV = {J. Vis.}}
@string{TVC = {The Vis. Comput.}}
@string{JCST = {J. Comput. Sci. Tech.}}
@string{CGF = {Comput. Graph. Forum}}
@string{CVM = {Computational Visual Media}}


@string{PAMI = {IEEE TPAMI}}
@string{IJCV = {IJCV}}
@string{CVPR = {CVPR}}
@string{ICCV = {ICCV}}
@string{ECCV = {ECCV}}
@string{NIPS = {NeurIPS}}
@string{ICPR = {ICPR}}
@string{BMVC = {BMVC}}
@string{TOG = {ACM TOG}}
@string{TIP = {IEEE TIP}}
@string{TVCG = {IEEE TVCG}}
@string{TCSVT = {IEEE TCSVT}}
@string{TMM = {IEEE TMM}}
@string{ACMMM = {ACM MM}}
@string{ICME = {ICME}}
@string{ICASSP = {ICASSP}}
@string{ICIP = {ICIP}}
@string{ACCV = {ACCV}}
@string{ICLR = {ICLR}}
@string{IJCAI = {IJCAI}}
@string{PR = {PR}}
@string{AAAI = {AAAI}}
@string{CVPRW = {CVPRW}}
@string{CSVT = {IEEE TCSVT}}


@misc{Authors14,
  author = {FirstName LastName},
  title = {The frobnicatable foo filter},
  note = {Face and Gesture submission ID 324. Supplied as supplemental material
          {\tt fg324.pdf}},
  year = 2014,
}


% https://arxiv.org/abs/1409.1556
@article{simonyan2014very,
  title = {Very deep convolutional networks for large-scale image recognition},
  author = {Simonyan, Karen and Zisserman, Andrew},
  journal = {arXiv:1409.1556},
  year = {2014},
}

% https://finance.yahoo.com/quote/GOOG/
@article{goog,
  title = {Alphabet Inc. (GOOG)},
  author = {Yahoo Finance},
  journal = {Yahoo Finance},
  year = {2024},
  url = {https://finance.yahoo.com/quote/GOOG/},
}

% https://pypi.org/project/yfinance/
@article{yfinance,
  title = {yfinance},
  author = {Ran Aroussi},
  journal = {PyPI},
  year = {2024},
  url = {https://pypi.org/project/yfinance/},
}

% https://machinelearningmastery.com/5-useful-loss-functions/
@article{loss_functions,
  title = {5 Useful Loss Functions},
  author = {Abid Ali Awan},
  journal = {Machine Learning Mastery},
  year = {2024},
  url = {https://machinelearningmastery.com/5-useful-loss-functions/},
}


% https://towardsdatascience.com/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf
@article{lstm,
  title = {Exploring the LSTM Neural Network Model for Time Series},
  author = {Michael Keith},
  journal = {Towards Data Science},
  year = {2022},
  url = {https://towardsdatascience.com/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf},
}

% https://www.geeksforgeeks.org/implementing-recurrent-neural-networks-in-pytorch/
@article{rnn_pytorch,
  title = {Implementing Recurrent Neural Networks in PyTorch},
  author = {GeeksforGeeks},
  journal = {GeeksforGeeks},
  year = {2024},
  url = {https://www.geeksforgeeks.org/implementing-recurrent-neural-networks-in-pytorch/},
}

